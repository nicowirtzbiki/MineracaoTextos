{
 "cells": [
  {
   "attachments": {
    "Unifor_logo.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Unifor_logo.png](attachment:Unifor_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINERAÇÃO DE TEXTOS E DA WEB\n",
    "\n",
    "## ATIVIDADE 01\n",
    "\n",
    "#### GRUPO 02:\n",
    "- Agenor Júnior\n",
    "- Nicole Wirtzbiki\n",
    "- Torricelli Evangelista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------\n",
    "INICIO ATIVIDADE 01 - Pré-processamento dos textos\n",
    "\n",
    "- Tokenização\n",
    "- Lematização\n",
    "- POS Tagging\n",
    "- Normalização\n",
    "- Chunking\n",
    "- NER (entidades nomeadas)\n",
    "- Remoção stop-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANTO PACOTES NECESSÁRIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('average_perceptron_tagger')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "language = \"english\"\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "import os\n",
    "#with redirect_stdout(open(os.devnull, \"w\")):\n",
    "    #nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Abertura do arquivo para tratamento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtask_c</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UNT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IND</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OFF</td>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT</td>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UNT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT</td>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OTH</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OFF</td>\n",
       "      <td>97670</td>\n",
       "      <td>@USER Liberals are all Kookoo !!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UNT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>77444</td>\n",
       "      <td>@USER @USER Oh noes! Tough shit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GRP</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OFF</td>\n",
       "      <td>52415</td>\n",
       "      <td>@USER was literally just talking about this lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT</td>\n",
       "      <td>45157</td>\n",
       "      <td>@USER Buy more icecream!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IND</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OFF</td>\n",
       "      <td>13384</td>\n",
       "      <td>@USER Canada doesn’t need another CUCK! We alr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subtask_c subtask_b subtask_a     id  \\\n",
       "0       NaN       UNT       OFF  86426   \n",
       "1       IND       TIN       OFF  90194   \n",
       "2       NaN       NaN       NOT  16820   \n",
       "3       NaN       UNT       OFF  62688   \n",
       "4       NaN       NaN       NOT  43605   \n",
       "5       OTH       TIN       OFF  97670   \n",
       "6       NaN       UNT       OFF  77444   \n",
       "7       GRP       TIN       OFF  52415   \n",
       "8       NaN       NaN       NOT  45157   \n",
       "9       IND       TIN       OFF  13384   \n",
       "\n",
       "                                               tweet  \n",
       "0  @USER She should ask a few native Americans wh...  \n",
       "1  @USER @USER Go home you’re drunk!!! @USER #MAG...  \n",
       "2  Amazon is investigating Chinese employees who ...  \n",
       "3  @USER Someone should'veTaken\" this piece of sh...  \n",
       "4  @USER @USER Obama wanted liberals &amp; illega...  \n",
       "5                  @USER Liberals are all Kookoo !!!  \n",
       "6                   @USER @USER Oh noes! Tough shit.  \n",
       "7  @USER was literally just talking about this lo...  \n",
       "8                         @USER Buy more icecream!!!  \n",
       "9  @USER Canada doesn’t need another CUCK! We alr...  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#leitura para objeto dataframe\n",
    "tweets = pd.read_csv('/home/nico/Área de Trabalho/MineracaoDadosWeb/entrega 2/olid-training-v1.0.tsv', sep='\\t',encoding= 'utf-8')\n",
    "\n",
    "#conversão da coluna 'id' de inteiro para string\n",
    "tweets['id'] = tweets['id'].astype('str')\n",
    "\n",
    "#visualização dos primeiros registros\n",
    "tweets = tweets[['subtask_c','subtask_b','subtask_a','id','tweet']]\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1- Uso da função \"print()\" para visualizar o arquivo na sua forma bruta.\n",
    "O arquivo corresponde a uma lista contendo 13240 strings. Cada string representa um tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tweets) # Imprime uma lista com 13240 strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Normalização\n",
    "\n",
    "entrada: tweet  |  saída: tweet_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Importando o módulo \"REGEX\" para expressões regulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_normalizado</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she should ask a few native americans what th...</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>86426</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go home youre drunk!      👊🇺🇸👊</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>90194</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>16820</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>62688</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama wanted liberals &amp;amp; illegals to move...</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>43605</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tweet_normalizado  \\\n",
       "0   she should ask a few native americans what th...   \n",
       "1                    go home youre drunk!      👊🇺🇸👊    \n",
       "2  amazon is investigating chinese employees who ...   \n",
       "3   someone shouldvetaken this piece of shit to a...   \n",
       "4    obama wanted liberals &amp; illegals to move...   \n",
       "\n",
       "                                               tweet     id subtask_a  \\\n",
       "0  @USER She should ask a few native Americans wh...  86426       OFF   \n",
       "1  @USER @USER Go home you’re drunk!!! @USER #MAG...  90194       OFF   \n",
       "2  Amazon is investigating Chinese employees who ...  16820       NOT   \n",
       "3  @USER Someone should'veTaken\" this piece of sh...  62688       OFF   \n",
       "4  @USER @USER Obama wanted liberals &amp; illega...  43605       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizacao_texto(tweet):\n",
    "    \n",
    "    #Normalização de todas as palavras para caixa baixa\n",
    "    tweet = tweet.lower() \n",
    "    \n",
    "    #Pela importância de manter pelo menos uma ocorrência de \"@user\" \n",
    "    #em cada tweet, foram removidas apenas suas repetições.\n",
    "    #tweet = re.sub('(@user |@user| @user )+',' @user ',tweet)\n",
    "    \n",
    "    #remove as menções a usuários de cada tweet\n",
    "    tweet = re.sub(r'@user', '', tweet, flags=re.MULTILINE)\n",
    "    \n",
    "    #Remoção de repetições seguidas de acentuações para não \n",
    "    #perder o sentido durante a análise do contexto dos tweets\n",
    "    tweet = re.sub('(!)+','!',tweet)\n",
    "    tweet = re.sub('(\")+','\"',tweet)\n",
    "    tweet = re.sub('(\\.)+','.',tweet)\n",
    "    \n",
    "    #Remoção de todas as palavras que começam com \"#\"\n",
    "    tweet = re.sub(r\"#(\\w+)\", ' ', tweet, flags=re.MULTILINE)\n",
    "      \n",
    "    #remove as palavras url\n",
    "    tweet = re.sub(r'url', '', tweet, flags=re.MULTILINE)\n",
    "    \n",
    "    #remove aspas e apóstofres\n",
    "    tweet = re.sub('[\\'\"‘’“”…]', '', tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "tweets['tweet_normalizado'] = tweets['tweet'].apply(normalizacao_texto)\n",
    "#tweets.head()  \n",
    "tweets[tweets.columns[::-1]].head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Tokenização\n",
    "entrada: tweet_normalizado | saída: tweet_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer, sent_tokenize\n",
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>tweet_normalizado</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[she, should, ask, a, few, native, americans,...</td>\n",
       "      <td>she should ask a few native americans what th...</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>86426</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>go home youre drunk!      👊🇺🇸👊</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>90194</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>16820</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[someone, shouldvetaken, this, piece, of, shi...</td>\n",
       "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>62688</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[obama, wanted, liberals, &amp;, illegals, to, mo...</td>\n",
       "      <td>obama wanted liberals &amp;amp; illegals to move...</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>43605</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        tweet_tokens  \\\n",
       "0  [[she, should, ask, a, few, native, americans,...   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, is, investigating, chinese, employee...   \n",
       "3  [[someone, shouldvetaken, this, piece, of, shi...   \n",
       "4  [[obama, wanted, liberals, &, illegals, to, mo...   \n",
       "\n",
       "                                   tweet_normalizado  \\\n",
       "0   she should ask a few native americans what th...   \n",
       "1                    go home youre drunk!      👊🇺🇸👊    \n",
       "2  amazon is investigating chinese employees who ...   \n",
       "3   someone shouldvetaken this piece of shit to a...   \n",
       "4    obama wanted liberals &amp; illegals to move...   \n",
       "\n",
       "                                               tweet     id subtask_a  \\\n",
       "0  @USER She should ask a few native Americans wh...  86426       OFF   \n",
       "1  @USER @USER Go home you’re drunk!!! @USER #MAG...  90194       OFF   \n",
       "2  Amazon is investigating Chinese employees who ...  16820       NOT   \n",
       "3  @USER Someone should'veTaken\" this piece of sh...  62688       OFF   \n",
       "4  @USER @USER Obama wanted liberals &amp; illega...  43605       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(tweet):\n",
    "    sents = sent_tokenize(tweet) #separando em sentenças\n",
    "    tokens = []\n",
    "    for word in sents:\n",
    "        tokens.append(tokenizer.tokenize(word)) #separando palavras\n",
    "    return tokens\n",
    "\n",
    "tweets['tweet_tokens'] = tweets['tweet_normalizado'].apply(tokenize)\n",
    "tweets[tweets.columns[::-1]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Remoção de Stop Words \n",
    "entrada: tweet_tokens | saída: tweet_tokens_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_chunked</th>\n",
       "      <th>tweet_lemma</th>\n",
       "      <th>tweet_tagged</th>\n",
       "      <th>tweet_tokens_sw</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>tweet_normalizado</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[(ask, RB, O), (native, JJ, B-NP), (americans...</td>\n",
       "      <td>[[ask, native, american, take, .]]</td>\n",
       "      <td>[[(ask, RB), (native, JJ), (americans, NNS), (...</td>\n",
       "      <td>[[ask, native, americans, take, .]]</td>\n",
       "      <td>[[she, should, ask, a, few, native, americans,...</td>\n",
       "      <td>she should ask a few native americans what th...</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>86426</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[(go, VB, O), (home, NN, B-NP), (youre, NN, I...</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>[[(go, VB), (home, NN), (youre, NN), (drunk, N...</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>go home youre drunk!      👊🇺🇸👊</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>90194</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[(amazon, NN, B-NP), (investigating, VBG, O),...</td>\n",
       "      <td>[[amazon, investigate, chinese, employee, sell...</td>\n",
       "      <td>[[(amazon, NN), (investigating, VBG), (chinese...</td>\n",
       "      <td>[[amazon, investigating, chinese, employees, s...</td>\n",
       "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>16820</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[(someone, NN, B-NP), (shouldvetaken, VBD, O)...</td>\n",
       "      <td>[[someone, shouldvetaken, piece, shit, volcano...</td>\n",
       "      <td>[[(someone, NN), (shouldvetaken, VBD), (piece,...</td>\n",
       "      <td>[[someone, shouldvetaken, piece, shit, volcano...</td>\n",
       "      <td>[[someone, shouldvetaken, this, piece, of, shi...</td>\n",
       "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>62688</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[(obama, RB, O), (wanted, VBD, O), (liberals,...</td>\n",
       "      <td>[[obama, want, liberal, &amp;, illegals, move, red...</td>\n",
       "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
       "      <td>[[obama, wanted, liberals, &amp;, illegals, move, ...</td>\n",
       "      <td>[[obama, wanted, liberals, &amp;, illegals, to, mo...</td>\n",
       "      <td>obama wanted liberals &amp;amp; illegals to move...</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>43605</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       tweet_chunked  \\\n",
       "0  [[(ask, RB, O), (native, JJ, B-NP), (americans...   \n",
       "1  [[(go, VB, O), (home, NN, B-NP), (youre, NN, I...   \n",
       "2  [[(amazon, NN, B-NP), (investigating, VBG, O),...   \n",
       "3  [[(someone, NN, B-NP), (shouldvetaken, VBD, O)...   \n",
       "4  [[(obama, RB, O), (wanted, VBD, O), (liberals,...   \n",
       "\n",
       "                                         tweet_lemma  \\\n",
       "0                 [[ask, native, american, take, .]]   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, investigate, chinese, employee, sell...   \n",
       "3  [[someone, shouldvetaken, piece, shit, volcano...   \n",
       "4  [[obama, want, liberal, &, illegals, move, red...   \n",
       "\n",
       "                                        tweet_tagged  \\\n",
       "0  [[(ask, RB), (native, JJ), (americans, NNS), (...   \n",
       "1  [[(go, VB), (home, NN), (youre, NN), (drunk, N...   \n",
       "2  [[(amazon, NN), (investigating, VBG), (chinese...   \n",
       "3  [[(someone, NN), (shouldvetaken, VBD), (piece,...   \n",
       "4  [[(obama, RB), (wanted, VBD), (liberals, NNS),...   \n",
       "\n",
       "                                     tweet_tokens_sw  \\\n",
       "0                [[ask, native, americans, take, .]]   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, investigating, chinese, employees, s...   \n",
       "3  [[someone, shouldvetaken, piece, shit, volcano...   \n",
       "4  [[obama, wanted, liberals, &, illegals, move, ...   \n",
       "\n",
       "                                        tweet_tokens  \\\n",
       "0  [[she, should, ask, a, few, native, americans,...   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, is, investigating, chinese, employee...   \n",
       "3  [[someone, shouldvetaken, this, piece, of, shi...   \n",
       "4  [[obama, wanted, liberals, &, illegals, to, mo...   \n",
       "\n",
       "                                   tweet_normalizado  \\\n",
       "0   she should ask a few native americans what th...   \n",
       "1                    go home youre drunk!      👊🇺🇸👊    \n",
       "2  amazon is investigating chinese employees who ...   \n",
       "3   someone shouldvetaken this piece of shit to a...   \n",
       "4    obama wanted liberals &amp; illegals to move...   \n",
       "\n",
       "                                               tweet     id subtask_a  \\\n",
       "0  @USER She should ask a few native Americans wh...  86426       OFF   \n",
       "1  @USER @USER Go home you’re drunk!!! @USER #MAG...  90194       OFF   \n",
       "2  Amazon is investigating Chinese employees who ...  16820       NOT   \n",
       "3  @USER Someone should'veTaken\" this piece of sh...  62688       OFF   \n",
       "4  @USER @USER Obama wanted liberals &amp; illega...  43605       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stop_words(sents_list):\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    out_list = []\n",
    "    \n",
    "    for tokens_list in sents_list:\n",
    "        tokens = [x for x in tokens_list if not x in stop_words]\n",
    "        out_list.append(tokens)\n",
    "        \n",
    "    return out_list\n",
    "\n",
    "   \n",
    "tweets['tweet_tokens_sw'] = tweets['tweet_tokens'].apply(remove_stop_words)\n",
    "tweets[tweets.columns[::-1]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - POS Tagger\n",
    "\n",
    "entrada: tweet_tokens_sw | saída: tweet_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_tagged</th>\n",
       "      <th>tweet_tokens_sw</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>tweet_normalizado</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[(ask, RB), (native, JJ), (americans, NNS), (...</td>\n",
       "      <td>[[ask, native, americans, take, .]]</td>\n",
       "      <td>[[she, should, ask, a, few, native, americans,...</td>\n",
       "      <td>she should ask a few native americans what th...</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>86426</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[(go, VB), (home, NN), (youre, NN), (drunk, N...</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>go home youre drunk!      👊🇺🇸👊</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>90194</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[(amazon, NN), (investigating, VBG), (chinese...</td>\n",
       "      <td>[[amazon, investigating, chinese, employees, s...</td>\n",
       "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>16820</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[(someone, NN), (shouldvetaken, VBD), (piece,...</td>\n",
       "      <td>[[someone, shouldvetaken, piece, shit, volcano...</td>\n",
       "      <td>[[someone, shouldvetaken, this, piece, of, shi...</td>\n",
       "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>62688</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
       "      <td>[[obama, wanted, liberals, &amp;, illegals, move, ...</td>\n",
       "      <td>[[obama, wanted, liberals, &amp;, illegals, to, mo...</td>\n",
       "      <td>obama wanted liberals &amp;amp; illegals to move...</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>43605</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        tweet_tagged  \\\n",
       "0  [[(ask, RB), (native, JJ), (americans, NNS), (...   \n",
       "1  [[(go, VB), (home, NN), (youre, NN), (drunk, N...   \n",
       "2  [[(amazon, NN), (investigating, VBG), (chinese...   \n",
       "3  [[(someone, NN), (shouldvetaken, VBD), (piece,...   \n",
       "4  [[(obama, RB), (wanted, VBD), (liberals, NNS),...   \n",
       "\n",
       "                                     tweet_tokens_sw  \\\n",
       "0                [[ask, native, americans, take, .]]   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, investigating, chinese, employees, s...   \n",
       "3  [[someone, shouldvetaken, piece, shit, volcano...   \n",
       "4  [[obama, wanted, liberals, &, illegals, move, ...   \n",
       "\n",
       "                                        tweet_tokens  \\\n",
       "0  [[she, should, ask, a, few, native, americans,...   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, is, investigating, chinese, employee...   \n",
       "3  [[someone, shouldvetaken, this, piece, of, shi...   \n",
       "4  [[obama, wanted, liberals, &, illegals, to, mo...   \n",
       "\n",
       "                                   tweet_normalizado  \\\n",
       "0   she should ask a few native americans what th...   \n",
       "1                    go home youre drunk!      👊🇺🇸👊    \n",
       "2  amazon is investigating chinese employees who ...   \n",
       "3   someone shouldvetaken this piece of shit to a...   \n",
       "4    obama wanted liberals &amp; illegals to move...   \n",
       "\n",
       "                                               tweet     id subtask_a  \\\n",
       "0  @USER She should ask a few native Americans wh...  86426       OFF   \n",
       "1  @USER @USER Go home you’re drunk!!! @USER #MAG...  90194       OFF   \n",
       "2  Amazon is investigating Chinese employees who ...  16820       NOT   \n",
       "3  @USER Someone should'veTaken\" this piece of sh...  62688       OFF   \n",
       "4  @USER @USER Obama wanted liberals &amp; illega...  43605       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_tagger(sent_tokens):\n",
    "    \n",
    "    sent_tagged = []\n",
    "    for token in sent_tokens:\n",
    "        sent_tagged.append(nltk.pos_tag(token))\n",
    "\n",
    "    return sent_tagged\n",
    "\n",
    "tweets['tweet_tagged'] = tweets['tweet_tokens_sw'].apply(pos_tagger)\n",
    "tweets[tweets.columns[::-1]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Lemmatização\n",
    "\n",
    "entrada: tweet_tagged | saída: tweet_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAPEANDO OS POS-TAGS DO NLTK PARA O FORMATO ACEITO PELO WORDNET LEMMATIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict = {\"J\": wn.ADJ,\n",
    "            \"N\": wn.NOUN,\n",
    "            \"V\": wn.VERB,\n",
    "            \"R\": wn.ADV}\n",
    "\n",
    "def extract_wnpostag_from_postag(tag):\n",
    "    \n",
    "    #pega a primeira letra da tag\n",
    "    #segundo parâmetro opcional caso haja chave ausente no dicionário \n",
    "    return tag_dict.get(tag[0].upper(), None)\n",
    "\n",
    "def lemmatize_tupla_word_postag(tupla):\n",
    "    \n",
    "    #retorna uma tupla na forma (wordString, posTagString) \n",
    "    #como ('guitar', 'NN'), retorna a palavra lematizada.\n",
    "    tag = extract_wnpostag_from_postag(tupla[1])    \n",
    "    return lemmatizer.lemmatize(tupla[0], tag) if tag is not None else tupla[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEMMATIZANDO OS TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_lemma</th>\n",
       "      <th>tweet_tagged</th>\n",
       "      <th>tweet_tokens_sw</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>tweet_normalizado</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[ask, native, american, take, .]]</td>\n",
       "      <td>[[(ask, RB), (native, JJ), (americans, NNS), (...</td>\n",
       "      <td>[[ask, native, americans, take, .]]</td>\n",
       "      <td>[[she, should, ask, a, few, native, americans,...</td>\n",
       "      <td>she should ask a few native americans what th...</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>86426</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>[[(go, VB), (home, NN), (youre, NN), (drunk, N...</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>go home youre drunk!      👊🇺🇸👊</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>90194</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[amazon, investigate, chinese, employee, sell...</td>\n",
       "      <td>[[(amazon, NN), (investigating, VBG), (chinese...</td>\n",
       "      <td>[[amazon, investigating, chinese, employees, s...</td>\n",
       "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>16820</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[someone, shouldvetaken, piece, shit, volcano...</td>\n",
       "      <td>[[(someone, NN), (shouldvetaken, VBD), (piece,...</td>\n",
       "      <td>[[someone, shouldvetaken, piece, shit, volcano...</td>\n",
       "      <td>[[someone, shouldvetaken, this, piece, of, shi...</td>\n",
       "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>62688</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[obama, want, liberal, &amp;, illegals, move, red...</td>\n",
       "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
       "      <td>[[obama, wanted, liberals, &amp;, illegals, move, ...</td>\n",
       "      <td>[[obama, wanted, liberals, &amp;, illegals, to, mo...</td>\n",
       "      <td>obama wanted liberals &amp;amp; illegals to move...</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>43605</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweet_lemma  \\\n",
       "0                 [[ask, native, american, take, .]]   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, investigate, chinese, employee, sell...   \n",
       "3  [[someone, shouldvetaken, piece, shit, volcano...   \n",
       "4  [[obama, want, liberal, &, illegals, move, red...   \n",
       "\n",
       "                                        tweet_tagged  \\\n",
       "0  [[(ask, RB), (native, JJ), (americans, NNS), (...   \n",
       "1  [[(go, VB), (home, NN), (youre, NN), (drunk, N...   \n",
       "2  [[(amazon, NN), (investigating, VBG), (chinese...   \n",
       "3  [[(someone, NN), (shouldvetaken, VBD), (piece,...   \n",
       "4  [[(obama, RB), (wanted, VBD), (liberals, NNS),...   \n",
       "\n",
       "                                     tweet_tokens_sw  \\\n",
       "0                [[ask, native, americans, take, .]]   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, investigating, chinese, employees, s...   \n",
       "3  [[someone, shouldvetaken, piece, shit, volcano...   \n",
       "4  [[obama, wanted, liberals, &, illegals, move, ...   \n",
       "\n",
       "                                        tweet_tokens  \\\n",
       "0  [[she, should, ask, a, few, native, americans,...   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, is, investigating, chinese, employee...   \n",
       "3  [[someone, shouldvetaken, this, piece, of, shi...   \n",
       "4  [[obama, wanted, liberals, &, illegals, to, mo...   \n",
       "\n",
       "                                   tweet_normalizado  \\\n",
       "0   she should ask a few native americans what th...   \n",
       "1                    go home youre drunk!      👊🇺🇸👊    \n",
       "2  amazon is investigating chinese employees who ...   \n",
       "3   someone shouldvetaken this piece of shit to a...   \n",
       "4    obama wanted liberals &amp; illegals to move...   \n",
       "\n",
       "                                               tweet     id subtask_a  \\\n",
       "0  @USER She should ask a few native Americans wh...  86426       OFF   \n",
       "1  @USER @USER Go home you’re drunk!!! @USER #MAG...  90194       OFF   \n",
       "2  Amazon is investigating Chinese employees who ...  16820       NOT   \n",
       "3  @USER Someone should'veTaken\" this piece of sh...  62688       OFF   \n",
       "4  @USER @USER Obama wanted liberals &amp; illega...  43605       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize_tweets(sent_list):\n",
    "    \n",
    "    out_list = []\n",
    "    for token in sent_list:\n",
    "        lemmas = [lemmatize_tupla_word_postag(x) for x in token]\n",
    "        out_list.append(lemmas)\n",
    "\n",
    "    return out_list\n",
    "\n",
    "tweets['tweet_lemma'] = tweets['tweet_tagged'].apply(lemmatize_tweets)\n",
    "tweets[tweets.columns[::-1]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Chunking\n",
    "\n",
    "entrada: tweet_tagged | saída: tweet_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "\n",
    "#with redirect_stdout(open(os.devnull, \"w\")):\n",
    "    #nltk.download('maxent_ne_chunker')\n",
    "    #nltk.download('words')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_chunked</th>\n",
       "      <th>tweet_lemma</th>\n",
       "      <th>tweet_tagged</th>\n",
       "      <th>tweet_tokens_sw</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>tweet_normalizado</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[(ask, RB, O), (native, JJ, B-NP), (americans...</td>\n",
       "      <td>[[ask, native, american, take, .]]</td>\n",
       "      <td>[[(ask, RB), (native, JJ), (americans, NNS), (...</td>\n",
       "      <td>[[ask, native, americans, take, .]]</td>\n",
       "      <td>[[she, should, ask, a, few, native, americans,...</td>\n",
       "      <td>she should ask a few native americans what th...</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>86426</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[(go, VB, O), (home, NN, B-NP), (youre, NN, I...</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>[[(go, VB), (home, NN), (youre, NN), (drunk, N...</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>go home youre drunk!      👊🇺🇸👊</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>90194</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[(amazon, NN, B-NP), (investigating, VBG, O),...</td>\n",
       "      <td>[[amazon, investigate, chinese, employee, sell...</td>\n",
       "      <td>[[(amazon, NN), (investigating, VBG), (chinese...</td>\n",
       "      <td>[[amazon, investigating, chinese, employees, s...</td>\n",
       "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>16820</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[(someone, NN, B-NP), (shouldvetaken, VBD, O)...</td>\n",
       "      <td>[[someone, shouldvetaken, piece, shit, volcano...</td>\n",
       "      <td>[[(someone, NN), (shouldvetaken, VBD), (piece,...</td>\n",
       "      <td>[[someone, shouldvetaken, piece, shit, volcano...</td>\n",
       "      <td>[[someone, shouldvetaken, this, piece, of, shi...</td>\n",
       "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>62688</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[(obama, RB, O), (wanted, VBD, O), (liberals,...</td>\n",
       "      <td>[[obama, want, liberal, &amp;, illegals, move, red...</td>\n",
       "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
       "      <td>[[obama, wanted, liberals, &amp;, illegals, move, ...</td>\n",
       "      <td>[[obama, wanted, liberals, &amp;, illegals, to, mo...</td>\n",
       "      <td>obama wanted liberals &amp;amp; illegals to move...</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>43605</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       tweet_chunked  \\\n",
       "0  [[(ask, RB, O), (native, JJ, B-NP), (americans...   \n",
       "1  [[(go, VB, O), (home, NN, B-NP), (youre, NN, I...   \n",
       "2  [[(amazon, NN, B-NP), (investigating, VBG, O),...   \n",
       "3  [[(someone, NN, B-NP), (shouldvetaken, VBD, O)...   \n",
       "4  [[(obama, RB, O), (wanted, VBD, O), (liberals,...   \n",
       "\n",
       "                                         tweet_lemma  \\\n",
       "0                 [[ask, native, american, take, .]]   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, investigate, chinese, employee, sell...   \n",
       "3  [[someone, shouldvetaken, piece, shit, volcano...   \n",
       "4  [[obama, want, liberal, &, illegals, move, red...   \n",
       "\n",
       "                                        tweet_tagged  \\\n",
       "0  [[(ask, RB), (native, JJ), (americans, NNS), (...   \n",
       "1  [[(go, VB), (home, NN), (youre, NN), (drunk, N...   \n",
       "2  [[(amazon, NN), (investigating, VBG), (chinese...   \n",
       "3  [[(someone, NN), (shouldvetaken, VBD), (piece,...   \n",
       "4  [[(obama, RB), (wanted, VBD), (liberals, NNS),...   \n",
       "\n",
       "                                     tweet_tokens_sw  \\\n",
       "0                [[ask, native, americans, take, .]]   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, investigating, chinese, employees, s...   \n",
       "3  [[someone, shouldvetaken, piece, shit, volcano...   \n",
       "4  [[obama, wanted, liberals, &, illegals, move, ...   \n",
       "\n",
       "                                        tweet_tokens  \\\n",
       "0  [[she, should, ask, a, few, native, americans,...   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, is, investigating, chinese, employee...   \n",
       "3  [[someone, shouldvetaken, this, piece, of, shi...   \n",
       "4  [[obama, wanted, liberals, &, illegals, to, mo...   \n",
       "\n",
       "                                   tweet_normalizado  \\\n",
       "0   she should ask a few native americans what th...   \n",
       "1                    go home youre drunk!      👊🇺🇸👊    \n",
       "2  amazon is investigating chinese employees who ...   \n",
       "3   someone shouldvetaken this piece of shit to a...   \n",
       "4    obama wanted liberals &amp; illegals to move...   \n",
       "\n",
       "                                               tweet     id subtask_a  \\\n",
       "0  @USER She should ask a few native Americans wh...  86426       OFF   \n",
       "1  @USER @USER Go home you’re drunk!!! @USER #MAG...  90194       OFF   \n",
       "2  Amazon is investigating Chinese employees who ...  16820       NOT   \n",
       "3  @USER Someone should'veTaken\" this piece of sh...  62688       OFF   \n",
       "4  @USER @USER Obama wanted liberals &amp; illega...  43605       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "\n",
    "def chunker (tweets_list):\n",
    "    \n",
    "    pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
    "    pattern1 = 'NP: {<DT>?<JJ>*<NN.*>*}'\n",
    "    pattern2 = 'NP: {<DT><NN.*><.*>*<NN.*>}'\n",
    "    \n",
    "    out_list = []\n",
    "    \n",
    "    for lista in tweets_list:\n",
    "        cp = nltk.RegexpParser(pattern1)\n",
    "        cs = cp.parse(lista)\n",
    "        \n",
    "        iob_tagged = tree2conlltags(cs)\n",
    "            \n",
    "        out_list.append(iob_tagged) \n",
    "        \n",
    "    return out_list\n",
    "\n",
    "tweets['tweet_chunked'] = tweets['tweet_tagged'].apply(chunker)\n",
    "tweets[tweets.columns[::-1]].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - NER - Reconhecimento de Entidades\n",
    "\n",
    "entrada: tweet_tagged | saída: tweet_NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "from nltk.chunk.regexp import ChunkString, ChunkRule, ChinkRule \n",
    "from nltk.tree import Tree \n",
    "from contextlib import redirect_stdout\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_NER</th>\n",
       "      <th>tweet_chunked</th>\n",
       "      <th>tweet_lemma</th>\n",
       "      <th>tweet_tagged</th>\n",
       "      <th>tweet_tokens_sw</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>tweet_normalizado</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[(ask, RB, O), (native, JJ, B-NP), (americans...</td>\n",
       "      <td>[[(ask, RB, O), (native, JJ, B-NP), (americans...</td>\n",
       "      <td>[[ask, native, american, take, .]]</td>\n",
       "      <td>[[(ask, RB), (native, JJ), (americans, NNS), (...</td>\n",
       "      <td>[[ask, native, americans, take, .]]</td>\n",
       "      <td>[[she, should, ask, a, few, native, americans,...</td>\n",
       "      <td>she should ask a few native americans what th...</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>86426</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[(go, VB, O), (home, NN, B-NP), (youre, NN, I...</td>\n",
       "      <td>[[(go, VB, O), (home, NN, B-NP), (youre, NN, I...</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>[[(go, VB), (home, NN), (youre, NN), (drunk, N...</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>[[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]</td>\n",
       "      <td>go home youre drunk!      👊🇺🇸👊</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>90194</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[(amazon, NN, B-NP), (investigating, VBG, O),...</td>\n",
       "      <td>[[(amazon, NN, B-NP), (investigating, VBG, O),...</td>\n",
       "      <td>[[amazon, investigate, chinese, employee, sell...</td>\n",
       "      <td>[[(amazon, NN), (investigating, VBG), (chinese...</td>\n",
       "      <td>[[amazon, investigating, chinese, employees, s...</td>\n",
       "      <td>[[amazon, is, investigating, chinese, employee...</td>\n",
       "      <td>amazon is investigating chinese employees who ...</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>16820</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[(someone, NN, B-NP), (shouldvetaken, VBD, O)...</td>\n",
       "      <td>[[(someone, NN, B-NP), (shouldvetaken, VBD, O)...</td>\n",
       "      <td>[[someone, shouldvetaken, piece, shit, volcano...</td>\n",
       "      <td>[[(someone, NN), (shouldvetaken, VBD), (piece,...</td>\n",
       "      <td>[[someone, shouldvetaken, piece, shit, volcano...</td>\n",
       "      <td>[[someone, shouldvetaken, this, piece, of, shi...</td>\n",
       "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>62688</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[(obama, RB, O), (wanted, VBD, O), (liberals,...</td>\n",
       "      <td>[[(obama, RB, O), (wanted, VBD, O), (liberals,...</td>\n",
       "      <td>[[obama, want, liberal, &amp;, illegals, move, red...</td>\n",
       "      <td>[[(obama, RB), (wanted, VBD), (liberals, NNS),...</td>\n",
       "      <td>[[obama, wanted, liberals, &amp;, illegals, move, ...</td>\n",
       "      <td>[[obama, wanted, liberals, &amp;, illegals, to, mo...</td>\n",
       "      <td>obama wanted liberals &amp;amp; illegals to move...</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>43605</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_NER  \\\n",
       "0  [[(ask, RB, O), (native, JJ, B-NP), (americans...   \n",
       "1  [[(go, VB, O), (home, NN, B-NP), (youre, NN, I...   \n",
       "2  [[(amazon, NN, B-NP), (investigating, VBG, O),...   \n",
       "3  [[(someone, NN, B-NP), (shouldvetaken, VBD, O)...   \n",
       "4  [[(obama, RB, O), (wanted, VBD, O), (liberals,...   \n",
       "\n",
       "                                       tweet_chunked  \\\n",
       "0  [[(ask, RB, O), (native, JJ, B-NP), (americans...   \n",
       "1  [[(go, VB, O), (home, NN, B-NP), (youre, NN, I...   \n",
       "2  [[(amazon, NN, B-NP), (investigating, VBG, O),...   \n",
       "3  [[(someone, NN, B-NP), (shouldvetaken, VBD, O)...   \n",
       "4  [[(obama, RB, O), (wanted, VBD, O), (liberals,...   \n",
       "\n",
       "                                         tweet_lemma  \\\n",
       "0                 [[ask, native, american, take, .]]   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, investigate, chinese, employee, sell...   \n",
       "3  [[someone, shouldvetaken, piece, shit, volcano...   \n",
       "4  [[obama, want, liberal, &, illegals, move, red...   \n",
       "\n",
       "                                        tweet_tagged  \\\n",
       "0  [[(ask, RB), (native, JJ), (americans, NNS), (...   \n",
       "1  [[(go, VB), (home, NN), (youre, NN), (drunk, N...   \n",
       "2  [[(amazon, NN), (investigating, VBG), (chinese...   \n",
       "3  [[(someone, NN), (shouldvetaken, VBD), (piece,...   \n",
       "4  [[(obama, RB), (wanted, VBD), (liberals, NNS),...   \n",
       "\n",
       "                                     tweet_tokens_sw  \\\n",
       "0                [[ask, native, americans, take, .]]   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, investigating, chinese, employees, s...   \n",
       "3  [[someone, shouldvetaken, piece, shit, volcano...   \n",
       "4  [[obama, wanted, liberals, &, illegals, move, ...   \n",
       "\n",
       "                                        tweet_tokens  \\\n",
       "0  [[she, should, ask, a, few, native, americans,...   \n",
       "1        [[go, home, youre, drunk, !], [👊, 🇺, 🇸, 👊]]   \n",
       "2  [[amazon, is, investigating, chinese, employee...   \n",
       "3  [[someone, shouldvetaken, this, piece, of, shi...   \n",
       "4  [[obama, wanted, liberals, &, illegals, to, mo...   \n",
       "\n",
       "                                   tweet_normalizado  \\\n",
       "0   she should ask a few native americans what th...   \n",
       "1                    go home youre drunk!      👊🇺🇸👊    \n",
       "2  amazon is investigating chinese employees who ...   \n",
       "3   someone shouldvetaken this piece of shit to a...   \n",
       "4    obama wanted liberals &amp; illegals to move...   \n",
       "\n",
       "                                               tweet     id subtask_a  \\\n",
       "0  @USER She should ask a few native Americans wh...  86426       OFF   \n",
       "1  @USER @USER Go home you’re drunk!!! @USER #MAG...  90194       OFF   \n",
       "2  Amazon is investigating Chinese employees who ...  16820       NOT   \n",
       "3  @USER Someone should'veTaken\" this piece of sh...  62688       OFF   \n",
       "4  @USER @USER Obama wanted liberals &amp; illega...  43605       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tweet_NER(tweets_list):\n",
    "    \n",
    "    out_list = []\n",
    "    for tweet in tweets_list:\n",
    "        out_list.append(nltk.ne_chunk(tweet))\n",
    "        \n",
    "    return out_list\n",
    "\n",
    "tweets['tweet_NER'] = tweets['tweet_tagged'].apply(chunker)\n",
    "tweets[tweets.columns[::-1]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produtos da Atividade 01:\n",
    "\n",
    "As entregas da atividade 01 são as listas:\n",
    "\n",
    "- tweet_lemma\n",
    "- tweet_chunked\n",
    "- tweet_NER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
